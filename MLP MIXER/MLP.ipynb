{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jM2bT9zO1HF"
      },
      "source": [
        "from torch import nn\n",
        "from einops.layers.torch import Rearrange\n",
        "import torch\n",
        "\n",
        "\n",
        "class MixerBlock(nn.Module):\n",
        "    def __init__(self, dim, patch):\n",
        "        super().__init__()\n",
        "        self.pre_layer_norm = nn.LayerNorm(dim)\n",
        "        self.post_layer_norm = nn.LayerNorm(dim)\n",
        "        \n",
        "        self.token_mixer = nn.Sequential(\n",
        "                            nn.Linear(patch, dim),\n",
        "                            nn.GELU(),\n",
        "                            nn.Dropout(0.1),\n",
        "                            nn.Linear(dim, patch),\n",
        "                            nn.Dropout(0.1)\n",
        "                            )\n",
        "        \n",
        "        self.channel_mixer = nn.Sequential(\n",
        "                            nn.Linear(dim, dim),\n",
        "                            nn.GELU(),\n",
        "                            nn.Dropout(0.1),\n",
        "                            nn.Linear(dim, dim),\n",
        "                            nn.Dropout(0.1)\n",
        "                            )\n",
        "    def forward(self, x):\n",
        "        z =self.pre_layer_norm(x)\n",
        "        y = self.token_mixer(z.transpose(1,2)).transpose(1,2)\n",
        "        y = y + x\n",
        "        post_ln = self.post_layer_norm(y)\n",
        "        cm_out = self.channel_mixer(post_ln)+y\n",
        "        return cm_out\n",
        "    \n",
        "    \n",
        "class MLPMixer(nn.Module):\n",
        "    def __init__(self,input_size, patch_size, dim = 512, img_channel=3, layers = 12, num_classes=12):\n",
        "        super().__init__()\n",
        "        patch = int(input_size[0]/patch_size[0] * input_size[1]/patch_size[1])\n",
        "        patch_dim = img_channel * patch_size[0] * patch_size[1]\n",
        "        self.embedding = nn.Sequential(\n",
        "                                                Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_size[0], p2 = patch_size[1]),\n",
        "                                                nn.Linear(patch_dim, dim)\n",
        "                                                )\n",
        "        self.main_architecture = nn.Sequential(*[nn.Sequential(MixerBlock(dim,patch)) for _ in range(layers)])\n",
        "        \n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.classifier = nn.Linear(dim,num_classes)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.main_architecture(x)\n",
        "        return self.classifier(self.pool(x.transpose(1,2)).squeeze(2))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64H1l7e4O9UW",
        "outputId": "7caae2f2-9eaa-429e-85d6-469d09ccfbea"
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "transform = transforms.Compose([transforms.Pad(4),transforms.RandomHorizontalFlip(),transforms.RandomCrop(32),transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "test_transform  = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5))])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='../../data/', train=True,transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='../../data/', train=False,transform=test_transform)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=100, shuffle=False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96kN8ZuJS4R8",
        "outputId": "ab22c605-4a1b-4844-a54c-74f7e8cf020e"
      },
      "source": [
        "model = MLPMixer(\n",
        "        input_size = (256,256),\n",
        "        patch_size = (1,256),\n",
        "        dim = 512,\n",
        "        layers = 12,\n",
        "        num_classes = 10,   \n",
        "        )\n",
        "img = torch.randn(10, 3, 256, 256)\n",
        "pred = model(img)\n",
        "pred.size()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41OcydsLPTO6",
        "outputId": "f8b660e4-a872-41be-f85d-6037fbeeb99a"
      },
      "source": [
        "import time \n",
        "device = \"cuda\"\n",
        "\n",
        "model = MLPMixer(\n",
        "        input_size = (32,32),\n",
        "        patch_size = (1,32),\n",
        "        dim = 512,\n",
        "        layers = 12,\n",
        "        num_classes = 10,   \n",
        "        ).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=lr_decay)\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=lr_decay)\n",
        "total_time = 0 \n",
        "epochs = 56\n",
        "for epoch in range(epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    start_time = time.time()\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step() \n",
        "    if (i+1) %500 == 0:\n",
        "      elapsed_time = time.time() - start_time\n",
        "      total_time += elapsed_time\n",
        "      print (\"Epoch {}, Step {} Loss: {:.4f} time : {:.4f}sec\".format(epoch+1, i+1, loss.item(),total_time))\n",
        " # scheduler.step()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#trainer.fit(model, train_dataloader=train_dl, val_dataloaders=val_dl)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Step 500 Loss: 1.5347 time : 0.1748sec\n",
            "Epoch 2, Step 500 Loss: 1.2596 time : 0.3491sec\n",
            "Epoch 3, Step 500 Loss: 1.3192 time : 0.5247sec\n",
            "Epoch 4, Step 500 Loss: 1.4859 time : 0.7010sec\n",
            "Epoch 5, Step 500 Loss: 1.0644 time : 0.8779sec\n",
            "Epoch 6, Step 500 Loss: 1.2136 time : 1.0528sec\n",
            "Epoch 7, Step 500 Loss: 1.2327 time : 1.2290sec\n",
            "Epoch 8, Step 500 Loss: 0.8495 time : 1.4095sec\n",
            "Epoch 9, Step 500 Loss: 1.0462 time : 1.5856sec\n",
            "Epoch 10, Step 500 Loss: 0.8641 time : 1.7606sec\n",
            "Epoch 11, Step 500 Loss: 0.7262 time : 1.9349sec\n",
            "Epoch 12, Step 500 Loss: 0.7857 time : 2.1098sec\n",
            "Epoch 13, Step 500 Loss: 0.8486 time : 2.2858sec\n",
            "Epoch 14, Step 500 Loss: 0.6858 time : 2.4617sec\n",
            "Epoch 15, Step 500 Loss: 0.7438 time : 2.6381sec\n",
            "Epoch 16, Step 500 Loss: 0.7348 time : 2.8130sec\n",
            "Epoch 17, Step 500 Loss: 0.7044 time : 2.9877sec\n",
            "Epoch 18, Step 500 Loss: 0.6365 time : 3.1628sec\n",
            "Epoch 19, Step 500 Loss: 0.6478 time : 3.3389sec\n",
            "Epoch 20, Step 500 Loss: 0.6265 time : 3.5148sec\n",
            "Epoch 21, Step 500 Loss: 0.7128 time : 3.6896sec\n",
            "Epoch 22, Step 500 Loss: 0.5392 time : 3.8649sec\n",
            "Epoch 23, Step 500 Loss: 0.4509 time : 4.0397sec\n",
            "Epoch 24, Step 500 Loss: 0.3963 time : 4.2151sec\n",
            "Epoch 25, Step 500 Loss: 0.4387 time : 4.3909sec\n",
            "Epoch 26, Step 500 Loss: 0.3983 time : 4.5642sec\n",
            "Epoch 27, Step 500 Loss: 0.2472 time : 4.7408sec\n",
            "Epoch 28, Step 500 Loss: 0.4294 time : 4.9156sec\n",
            "Epoch 29, Step 500 Loss: 0.2669 time : 5.0910sec\n",
            "Epoch 30, Step 500 Loss: 0.3183 time : 5.2674sec\n",
            "Epoch 31, Step 500 Loss: 0.1760 time : 5.4418sec\n",
            "Epoch 32, Step 500 Loss: 0.3019 time : 5.6170sec\n",
            "Epoch 33, Step 500 Loss: 0.1700 time : 5.7925sec\n",
            "Epoch 34, Step 500 Loss: 0.2904 time : 5.9674sec\n",
            "Epoch 35, Step 500 Loss: 0.1853 time : 6.1435sec\n",
            "Epoch 36, Step 500 Loss: 0.3745 time : 6.3185sec\n",
            "Epoch 37, Step 500 Loss: 0.2144 time : 6.4933sec\n",
            "Epoch 38, Step 500 Loss: 0.3126 time : 6.6702sec\n",
            "Epoch 39, Step 500 Loss: 0.1316 time : 6.8464sec\n",
            "Epoch 40, Step 500 Loss: 0.2988 time : 7.0205sec\n",
            "Epoch 41, Step 500 Loss: 0.2236 time : 7.1957sec\n",
            "Epoch 42, Step 500 Loss: 0.1354 time : 7.3707sec\n",
            "Epoch 43, Step 500 Loss: 0.2724 time : 7.5463sec\n",
            "Epoch 44, Step 500 Loss: 0.1218 time : 7.7230sec\n",
            "Epoch 45, Step 500 Loss: 0.1051 time : 7.8982sec\n",
            "Epoch 46, Step 500 Loss: 0.3501 time : 8.0736sec\n",
            "Epoch 47, Step 500 Loss: 0.2126 time : 8.2484sec\n",
            "Epoch 48, Step 500 Loss: 0.1946 time : 8.4237sec\n",
            "Epoch 49, Step 500 Loss: 0.1800 time : 8.5994sec\n",
            "Epoch 50, Step 500 Loss: 0.1901 time : 8.7759sec\n",
            "Epoch 51, Step 500 Loss: 0.1441 time : 8.9537sec\n",
            "Epoch 52, Step 500 Loss: 0.1144 time : 9.1295sec\n",
            "Epoch 53, Step 500 Loss: 0.1464 time : 9.3038sec\n",
            "Epoch 54, Step 500 Loss: 0.1083 time : 9.4787sec\n",
            "Epoch 55, Step 500 Loss: 0.1530 time : 9.6544sec\n",
            "Epoch 56, Step 500 Loss: 0.1089 time : 9.8294sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2fEAY_qPmaq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d37ba42d-6447-4eb0-d12e-5f2ca3513e0e"
      },
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct =0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    print('Accuracy ( test images ) : {} %'.format(100 * correct / total))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy ( test images ) : 90.1 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HGKk4WRZz40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c26f5b9-9465-41e6-d182-e4890a7c3066"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model_stats = summary(model, (3, 32, 32))\n",
        "summary_str = str(model_stats)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "         Rearrange-1               [-1, 32, 96]               0\n",
            "            Linear-2              [-1, 32, 512]          49,664\n",
            "         LayerNorm-3              [-1, 32, 512]           1,024\n",
            "            Linear-4             [-1, 512, 512]          16,896\n",
            "              GELU-5             [-1, 512, 512]               0\n",
            "           Dropout-6             [-1, 512, 512]               0\n",
            "            Linear-7              [-1, 512, 32]          16,416\n",
            "           Dropout-8              [-1, 512, 32]               0\n",
            "         LayerNorm-9              [-1, 32, 512]           1,024\n",
            "           Linear-10              [-1, 32, 512]         262,656\n",
            "             GELU-11              [-1, 32, 512]               0\n",
            "          Dropout-12              [-1, 32, 512]               0\n",
            "           Linear-13              [-1, 32, 512]         262,656\n",
            "          Dropout-14              [-1, 32, 512]               0\n",
            "       MixerBlock-15              [-1, 32, 512]               0\n",
            "        LayerNorm-16              [-1, 32, 512]           1,024\n",
            "           Linear-17             [-1, 512, 512]          16,896\n",
            "             GELU-18             [-1, 512, 512]               0\n",
            "          Dropout-19             [-1, 512, 512]               0\n",
            "           Linear-20              [-1, 512, 32]          16,416\n",
            "          Dropout-21              [-1, 512, 32]               0\n",
            "        LayerNorm-22              [-1, 32, 512]           1,024\n",
            "           Linear-23              [-1, 32, 512]         262,656\n",
            "             GELU-24              [-1, 32, 512]               0\n",
            "          Dropout-25              [-1, 32, 512]               0\n",
            "           Linear-26              [-1, 32, 512]         262,656\n",
            "          Dropout-27              [-1, 32, 512]               0\n",
            "       MixerBlock-28              [-1, 32, 512]               0\n",
            "        LayerNorm-29              [-1, 32, 512]           1,024\n",
            "           Linear-30             [-1, 512, 512]          16,896\n",
            "             GELU-31             [-1, 512, 512]               0\n",
            "          Dropout-32             [-1, 512, 512]               0\n",
            "           Linear-33              [-1, 512, 32]          16,416\n",
            "          Dropout-34              [-1, 512, 32]               0\n",
            "        LayerNorm-35              [-1, 32, 512]           1,024\n",
            "           Linear-36              [-1, 32, 512]         262,656\n",
            "             GELU-37              [-1, 32, 512]               0\n",
            "          Dropout-38              [-1, 32, 512]               0\n",
            "           Linear-39              [-1, 32, 512]         262,656\n",
            "          Dropout-40              [-1, 32, 512]               0\n",
            "       MixerBlock-41              [-1, 32, 512]               0\n",
            "        LayerNorm-42              [-1, 32, 512]           1,024\n",
            "           Linear-43             [-1, 512, 512]          16,896\n",
            "             GELU-44             [-1, 512, 512]               0\n",
            "          Dropout-45             [-1, 512, 512]               0\n",
            "           Linear-46              [-1, 512, 32]          16,416\n",
            "          Dropout-47              [-1, 512, 32]               0\n",
            "        LayerNorm-48              [-1, 32, 512]           1,024\n",
            "           Linear-49              [-1, 32, 512]         262,656\n",
            "             GELU-50              [-1, 32, 512]               0\n",
            "          Dropout-51              [-1, 32, 512]               0\n",
            "           Linear-52              [-1, 32, 512]         262,656\n",
            "          Dropout-53              [-1, 32, 512]               0\n",
            "       MixerBlock-54              [-1, 32, 512]               0\n",
            "        LayerNorm-55              [-1, 32, 512]           1,024\n",
            "           Linear-56             [-1, 512, 512]          16,896\n",
            "             GELU-57             [-1, 512, 512]               0\n",
            "          Dropout-58             [-1, 512, 512]               0\n",
            "           Linear-59              [-1, 512, 32]          16,416\n",
            "          Dropout-60              [-1, 512, 32]               0\n",
            "        LayerNorm-61              [-1, 32, 512]           1,024\n",
            "           Linear-62              [-1, 32, 512]         262,656\n",
            "             GELU-63              [-1, 32, 512]               0\n",
            "          Dropout-64              [-1, 32, 512]               0\n",
            "           Linear-65              [-1, 32, 512]         262,656\n",
            "          Dropout-66              [-1, 32, 512]               0\n",
            "       MixerBlock-67              [-1, 32, 512]               0\n",
            "        LayerNorm-68              [-1, 32, 512]           1,024\n",
            "           Linear-69             [-1, 512, 512]          16,896\n",
            "             GELU-70             [-1, 512, 512]               0\n",
            "          Dropout-71             [-1, 512, 512]               0\n",
            "           Linear-72              [-1, 512, 32]          16,416\n",
            "          Dropout-73              [-1, 512, 32]               0\n",
            "        LayerNorm-74              [-1, 32, 512]           1,024\n",
            "           Linear-75              [-1, 32, 512]         262,656\n",
            "             GELU-76              [-1, 32, 512]               0\n",
            "          Dropout-77              [-1, 32, 512]               0\n",
            "           Linear-78              [-1, 32, 512]         262,656\n",
            "          Dropout-79              [-1, 32, 512]               0\n",
            "       MixerBlock-80              [-1, 32, 512]               0\n",
            "        LayerNorm-81              [-1, 32, 512]           1,024\n",
            "           Linear-82             [-1, 512, 512]          16,896\n",
            "             GELU-83             [-1, 512, 512]               0\n",
            "          Dropout-84             [-1, 512, 512]               0\n",
            "           Linear-85              [-1, 512, 32]          16,416\n",
            "          Dropout-86              [-1, 512, 32]               0\n",
            "        LayerNorm-87              [-1, 32, 512]           1,024\n",
            "           Linear-88              [-1, 32, 512]         262,656\n",
            "             GELU-89              [-1, 32, 512]               0\n",
            "          Dropout-90              [-1, 32, 512]               0\n",
            "           Linear-91              [-1, 32, 512]         262,656\n",
            "          Dropout-92              [-1, 32, 512]               0\n",
            "       MixerBlock-93              [-1, 32, 512]               0\n",
            "        LayerNorm-94              [-1, 32, 512]           1,024\n",
            "           Linear-95             [-1, 512, 512]          16,896\n",
            "             GELU-96             [-1, 512, 512]               0\n",
            "          Dropout-97             [-1, 512, 512]               0\n",
            "           Linear-98              [-1, 512, 32]          16,416\n",
            "          Dropout-99              [-1, 512, 32]               0\n",
            "       LayerNorm-100              [-1, 32, 512]           1,024\n",
            "          Linear-101              [-1, 32, 512]         262,656\n",
            "            GELU-102              [-1, 32, 512]               0\n",
            "         Dropout-103              [-1, 32, 512]               0\n",
            "          Linear-104              [-1, 32, 512]         262,656\n",
            "         Dropout-105              [-1, 32, 512]               0\n",
            "      MixerBlock-106              [-1, 32, 512]               0\n",
            "       LayerNorm-107              [-1, 32, 512]           1,024\n",
            "          Linear-108             [-1, 512, 512]          16,896\n",
            "            GELU-109             [-1, 512, 512]               0\n",
            "         Dropout-110             [-1, 512, 512]               0\n",
            "          Linear-111              [-1, 512, 32]          16,416\n",
            "         Dropout-112              [-1, 512, 32]               0\n",
            "       LayerNorm-113              [-1, 32, 512]           1,024\n",
            "          Linear-114              [-1, 32, 512]         262,656\n",
            "            GELU-115              [-1, 32, 512]               0\n",
            "         Dropout-116              [-1, 32, 512]               0\n",
            "          Linear-117              [-1, 32, 512]         262,656\n",
            "         Dropout-118              [-1, 32, 512]               0\n",
            "      MixerBlock-119              [-1, 32, 512]               0\n",
            "       LayerNorm-120              [-1, 32, 512]           1,024\n",
            "          Linear-121             [-1, 512, 512]          16,896\n",
            "            GELU-122             [-1, 512, 512]               0\n",
            "         Dropout-123             [-1, 512, 512]               0\n",
            "          Linear-124              [-1, 512, 32]          16,416\n",
            "         Dropout-125              [-1, 512, 32]               0\n",
            "       LayerNorm-126              [-1, 32, 512]           1,024\n",
            "          Linear-127              [-1, 32, 512]         262,656\n",
            "            GELU-128              [-1, 32, 512]               0\n",
            "         Dropout-129              [-1, 32, 512]               0\n",
            "          Linear-130              [-1, 32, 512]         262,656\n",
            "         Dropout-131              [-1, 32, 512]               0\n",
            "      MixerBlock-132              [-1, 32, 512]               0\n",
            "       LayerNorm-133              [-1, 32, 512]           1,024\n",
            "          Linear-134             [-1, 512, 512]          16,896\n",
            "            GELU-135             [-1, 512, 512]               0\n",
            "         Dropout-136             [-1, 512, 512]               0\n",
            "          Linear-137              [-1, 512, 32]          16,416\n",
            "         Dropout-138              [-1, 512, 32]               0\n",
            "       LayerNorm-139              [-1, 32, 512]           1,024\n",
            "          Linear-140              [-1, 32, 512]         262,656\n",
            "            GELU-141              [-1, 32, 512]               0\n",
            "         Dropout-142              [-1, 32, 512]               0\n",
            "          Linear-143              [-1, 32, 512]         262,656\n",
            "         Dropout-144              [-1, 32, 512]               0\n",
            "      MixerBlock-145              [-1, 32, 512]               0\n",
            "       LayerNorm-146              [-1, 32, 512]           1,024\n",
            "          Linear-147             [-1, 512, 512]          16,896\n",
            "            GELU-148             [-1, 512, 512]               0\n",
            "         Dropout-149             [-1, 512, 512]               0\n",
            "          Linear-150              [-1, 512, 32]          16,416\n",
            "         Dropout-151              [-1, 512, 32]               0\n",
            "       LayerNorm-152              [-1, 32, 512]           1,024\n",
            "          Linear-153              [-1, 32, 512]         262,656\n",
            "            GELU-154              [-1, 32, 512]               0\n",
            "         Dropout-155              [-1, 32, 512]               0\n",
            "          Linear-156              [-1, 32, 512]         262,656\n",
            "         Dropout-157              [-1, 32, 512]               0\n",
            "      MixerBlock-158              [-1, 32, 512]               0\n",
            "AdaptiveAvgPool1d-159               [-1, 512, 1]               0\n",
            "          Linear-160                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 6,782,858\n",
            "Trainable params: 6,782,858\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 87.15\n",
            "Params size (MB): 25.87\n",
            "Estimated Total Size (MB): 113.04\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}