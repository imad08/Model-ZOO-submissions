{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model and summary .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "d8803ujheqzI"
      },
      "source": [
        "class block(nn.Module):\n",
        "\n",
        "    def __init__(self,in_channels=None,out_channels=None,stride=None):\n",
        "        super(block,self).__init__()\n",
        "        self.stride = stride \n",
        "        self.in_channels = in_channels \n",
        "        self.out_channels = out_channels\n",
        "        self.nl = nn.ReLU()\n",
        "        #self.s = nn.Identity()\n",
        "        b1 = [nn.Conv2d(in_channels=self.in_channels, out_channels=self.out_channels,\n",
        "                                                  kernel_size=(3,3), stride=self.stride, padding=(1,1)),nn.BatchNorm2d(num_features=self.out_channels)]\n",
        "        self.x = nn.Sequential(*b1)\n",
        "        b2 = [nn.Conv2d(in_channels=self.in_channels, out_channels=self.out_channels,\n",
        "                                                  kernel_size=(1,1), stride=self.stride, padding=(0,0)),nn.BatchNorm2d(num_features=self.out_channels)]\n",
        "        self.y = nn.Sequential(*b2)\n",
        "        if self.stride == (1,1):\n",
        "          self.z = nn.Identity()\n",
        "        else :\n",
        "          self.z =None\n",
        "\n",
        "    def forward(self,input):\n",
        "        if self.z == None :\n",
        "            out = self.x(input) + self.y(input)\n",
        "        else :\n",
        "            out = self.x(input) + self.y(input) +self.z(input)\n",
        "        out = self.nl(out)\n",
        "        return out \n",
        "\n",
        "\n",
        "class REPVGG(nn.Module):\n",
        "\n",
        "          def __init__(self,in_channels=3,num_classes=10,blocks=None,multipl=None):\n",
        "            super(REPVGG,self).__init__()\n",
        "            self.blocks= blocks\n",
        "            self.multipl= multipl \n",
        "            self.in_channels = in_channels\n",
        "            self.main_REPVGG = self.main_architecture()\n",
        "            self.g = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "            self.linear = nn.Linear(int(512 * multipl[3]), num_classes)                               \n",
        "          \n",
        "          def main_architecture(self):\n",
        "                    layers = []\n",
        "\n",
        "\n",
        "                    #stage0\n",
        "\n",
        "                    \n",
        "                    multipl = self.multipl\n",
        "                    out_channels = min(64,int(64*multipl[0])) \n",
        "                    in_channels = self.in_channels\n",
        "                    blocks = self.blocks\n",
        "                    layers += [block(in_channels = in_channels,out_channels=out_channels,stride = (2,2))]\n",
        "                    in_channels = min(64, int(64*multipl[0]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                    #stage1,stage2,stage3,stage4\n",
        "\n",
        "\n",
        "\n",
        "                    for i in range(4):\n",
        "\n",
        "                      out_channels = int(64*(2**i) * multipl[i])\n",
        "                      layers += [block(in_channels = in_channels,out_channels=out_channels,stride = (2,2))]\n",
        "                      in_channels = out_channels\n",
        "\n",
        "                      for j in range(blocks[i]-1):\n",
        "                        layers += [block(in_channels = in_channels,out_channels=out_channels,stride = (1,1))]\n",
        "                      in_channels = out_channels \n",
        "\n",
        "                    return nn.Sequential(*layers)\n",
        "\n",
        "          def forward(self,x):\n",
        "            x = self.main_REPVGG(x)\n",
        "            x = self.g(x)\n",
        "            x = x.view(x.size(0), -1)\n",
        "            x = self.linear(x)\n",
        "            return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rl0j6YKMeydN",
        "outputId": "bf30ad6f-9736-451a-9bec-1c25be97bed4"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model_stats = summary(model, (3, 224, 224))\n",
        "summary_str = str(model_stats)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 48, 112, 112]           1,344\n",
            "       BatchNorm2d-2         [-1, 48, 112, 112]              96\n",
            "            Conv2d-3         [-1, 48, 112, 112]             192\n",
            "       BatchNorm2d-4         [-1, 48, 112, 112]              96\n",
            "              ReLU-5         [-1, 48, 112, 112]               0\n",
            "             block-6         [-1, 48, 112, 112]               0\n",
            "            Conv2d-7           [-1, 48, 56, 56]          20,784\n",
            "       BatchNorm2d-8           [-1, 48, 56, 56]              96\n",
            "            Conv2d-9           [-1, 48, 56, 56]           2,352\n",
            "      BatchNorm2d-10           [-1, 48, 56, 56]              96\n",
            "             ReLU-11           [-1, 48, 56, 56]               0\n",
            "            block-12           [-1, 48, 56, 56]               0\n",
            "           Conv2d-13           [-1, 48, 56, 56]          20,784\n",
            "      BatchNorm2d-14           [-1, 48, 56, 56]              96\n",
            "           Conv2d-15           [-1, 48, 56, 56]           2,352\n",
            "      BatchNorm2d-16           [-1, 48, 56, 56]              96\n",
            "         Identity-17           [-1, 48, 56, 56]               0\n",
            "             ReLU-18           [-1, 48, 56, 56]               0\n",
            "            block-19           [-1, 48, 56, 56]               0\n",
            "           Conv2d-20           [-1, 96, 28, 28]          41,568\n",
            "      BatchNorm2d-21           [-1, 96, 28, 28]             192\n",
            "           Conv2d-22           [-1, 96, 28, 28]           4,704\n",
            "      BatchNorm2d-23           [-1, 96, 28, 28]             192\n",
            "             ReLU-24           [-1, 96, 28, 28]               0\n",
            "            block-25           [-1, 96, 28, 28]               0\n",
            "           Conv2d-26           [-1, 96, 28, 28]          83,040\n",
            "      BatchNorm2d-27           [-1, 96, 28, 28]             192\n",
            "           Conv2d-28           [-1, 96, 28, 28]           9,312\n",
            "      BatchNorm2d-29           [-1, 96, 28, 28]             192\n",
            "         Identity-30           [-1, 96, 28, 28]               0\n",
            "             ReLU-31           [-1, 96, 28, 28]               0\n",
            "            block-32           [-1, 96, 28, 28]               0\n",
            "           Conv2d-33           [-1, 96, 28, 28]          83,040\n",
            "      BatchNorm2d-34           [-1, 96, 28, 28]             192\n",
            "           Conv2d-35           [-1, 96, 28, 28]           9,312\n",
            "      BatchNorm2d-36           [-1, 96, 28, 28]             192\n",
            "         Identity-37           [-1, 96, 28, 28]               0\n",
            "             ReLU-38           [-1, 96, 28, 28]               0\n",
            "            block-39           [-1, 96, 28, 28]               0\n",
            "           Conv2d-40           [-1, 96, 28, 28]          83,040\n",
            "      BatchNorm2d-41           [-1, 96, 28, 28]             192\n",
            "           Conv2d-42           [-1, 96, 28, 28]           9,312\n",
            "      BatchNorm2d-43           [-1, 96, 28, 28]             192\n",
            "         Identity-44           [-1, 96, 28, 28]               0\n",
            "             ReLU-45           [-1, 96, 28, 28]               0\n",
            "            block-46           [-1, 96, 28, 28]               0\n",
            "           Conv2d-47          [-1, 192, 14, 14]         166,080\n",
            "      BatchNorm2d-48          [-1, 192, 14, 14]             384\n",
            "           Conv2d-49          [-1, 192, 14, 14]          18,624\n",
            "      BatchNorm2d-50          [-1, 192, 14, 14]             384\n",
            "             ReLU-51          [-1, 192, 14, 14]               0\n",
            "            block-52          [-1, 192, 14, 14]               0\n",
            "           Conv2d-53          [-1, 192, 14, 14]         331,968\n",
            "      BatchNorm2d-54          [-1, 192, 14, 14]             384\n",
            "           Conv2d-55          [-1, 192, 14, 14]          37,056\n",
            "      BatchNorm2d-56          [-1, 192, 14, 14]             384\n",
            "         Identity-57          [-1, 192, 14, 14]               0\n",
            "             ReLU-58          [-1, 192, 14, 14]               0\n",
            "            block-59          [-1, 192, 14, 14]               0\n",
            "           Conv2d-60          [-1, 192, 14, 14]         331,968\n",
            "      BatchNorm2d-61          [-1, 192, 14, 14]             384\n",
            "           Conv2d-62          [-1, 192, 14, 14]          37,056\n",
            "      BatchNorm2d-63          [-1, 192, 14, 14]             384\n",
            "         Identity-64          [-1, 192, 14, 14]               0\n",
            "             ReLU-65          [-1, 192, 14, 14]               0\n",
            "            block-66          [-1, 192, 14, 14]               0\n",
            "           Conv2d-67          [-1, 192, 14, 14]         331,968\n",
            "      BatchNorm2d-68          [-1, 192, 14, 14]             384\n",
            "           Conv2d-69          [-1, 192, 14, 14]          37,056\n",
            "      BatchNorm2d-70          [-1, 192, 14, 14]             384\n",
            "         Identity-71          [-1, 192, 14, 14]               0\n",
            "             ReLU-72          [-1, 192, 14, 14]               0\n",
            "            block-73          [-1, 192, 14, 14]               0\n",
            "           Conv2d-74          [-1, 192, 14, 14]         331,968\n",
            "      BatchNorm2d-75          [-1, 192, 14, 14]             384\n",
            "           Conv2d-76          [-1, 192, 14, 14]          37,056\n",
            "      BatchNorm2d-77          [-1, 192, 14, 14]             384\n",
            "         Identity-78          [-1, 192, 14, 14]               0\n",
            "             ReLU-79          [-1, 192, 14, 14]               0\n",
            "            block-80          [-1, 192, 14, 14]               0\n",
            "           Conv2d-81          [-1, 192, 14, 14]         331,968\n",
            "      BatchNorm2d-82          [-1, 192, 14, 14]             384\n",
            "           Conv2d-83          [-1, 192, 14, 14]          37,056\n",
            "      BatchNorm2d-84          [-1, 192, 14, 14]             384\n",
            "         Identity-85          [-1, 192, 14, 14]               0\n",
            "             ReLU-86          [-1, 192, 14, 14]               0\n",
            "            block-87          [-1, 192, 14, 14]               0\n",
            "           Conv2d-88          [-1, 192, 14, 14]         331,968\n",
            "      BatchNorm2d-89          [-1, 192, 14, 14]             384\n",
            "           Conv2d-90          [-1, 192, 14, 14]          37,056\n",
            "      BatchNorm2d-91          [-1, 192, 14, 14]             384\n",
            "         Identity-92          [-1, 192, 14, 14]               0\n",
            "             ReLU-93          [-1, 192, 14, 14]               0\n",
            "            block-94          [-1, 192, 14, 14]               0\n",
            "           Conv2d-95          [-1, 192, 14, 14]         331,968\n",
            "      BatchNorm2d-96          [-1, 192, 14, 14]             384\n",
            "           Conv2d-97          [-1, 192, 14, 14]          37,056\n",
            "      BatchNorm2d-98          [-1, 192, 14, 14]             384\n",
            "         Identity-99          [-1, 192, 14, 14]               0\n",
            "            ReLU-100          [-1, 192, 14, 14]               0\n",
            "           block-101          [-1, 192, 14, 14]               0\n",
            "          Conv2d-102          [-1, 192, 14, 14]         331,968\n",
            "     BatchNorm2d-103          [-1, 192, 14, 14]             384\n",
            "          Conv2d-104          [-1, 192, 14, 14]          37,056\n",
            "     BatchNorm2d-105          [-1, 192, 14, 14]             384\n",
            "        Identity-106          [-1, 192, 14, 14]               0\n",
            "            ReLU-107          [-1, 192, 14, 14]               0\n",
            "           block-108          [-1, 192, 14, 14]               0\n",
            "          Conv2d-109          [-1, 192, 14, 14]         331,968\n",
            "     BatchNorm2d-110          [-1, 192, 14, 14]             384\n",
            "          Conv2d-111          [-1, 192, 14, 14]          37,056\n",
            "     BatchNorm2d-112          [-1, 192, 14, 14]             384\n",
            "        Identity-113          [-1, 192, 14, 14]               0\n",
            "            ReLU-114          [-1, 192, 14, 14]               0\n",
            "           block-115          [-1, 192, 14, 14]               0\n",
            "          Conv2d-116          [-1, 192, 14, 14]         331,968\n",
            "     BatchNorm2d-117          [-1, 192, 14, 14]             384\n",
            "          Conv2d-118          [-1, 192, 14, 14]          37,056\n",
            "     BatchNorm2d-119          [-1, 192, 14, 14]             384\n",
            "        Identity-120          [-1, 192, 14, 14]               0\n",
            "            ReLU-121          [-1, 192, 14, 14]               0\n",
            "           block-122          [-1, 192, 14, 14]               0\n",
            "          Conv2d-123          [-1, 192, 14, 14]         331,968\n",
            "     BatchNorm2d-124          [-1, 192, 14, 14]             384\n",
            "          Conv2d-125          [-1, 192, 14, 14]          37,056\n",
            "     BatchNorm2d-126          [-1, 192, 14, 14]             384\n",
            "        Identity-127          [-1, 192, 14, 14]               0\n",
            "            ReLU-128          [-1, 192, 14, 14]               0\n",
            "           block-129          [-1, 192, 14, 14]               0\n",
            "          Conv2d-130          [-1, 192, 14, 14]         331,968\n",
            "     BatchNorm2d-131          [-1, 192, 14, 14]             384\n",
            "          Conv2d-132          [-1, 192, 14, 14]          37,056\n",
            "     BatchNorm2d-133          [-1, 192, 14, 14]             384\n",
            "        Identity-134          [-1, 192, 14, 14]               0\n",
            "            ReLU-135          [-1, 192, 14, 14]               0\n",
            "           block-136          [-1, 192, 14, 14]               0\n",
            "          Conv2d-137          [-1, 192, 14, 14]         331,968\n",
            "     BatchNorm2d-138          [-1, 192, 14, 14]             384\n",
            "          Conv2d-139          [-1, 192, 14, 14]          37,056\n",
            "     BatchNorm2d-140          [-1, 192, 14, 14]             384\n",
            "        Identity-141          [-1, 192, 14, 14]               0\n",
            "            ReLU-142          [-1, 192, 14, 14]               0\n",
            "           block-143          [-1, 192, 14, 14]               0\n",
            "          Conv2d-144           [-1, 1280, 7, 7]       2,213,120\n",
            "     BatchNorm2d-145           [-1, 1280, 7, 7]           2,560\n",
            "          Conv2d-146           [-1, 1280, 7, 7]         247,040\n",
            "     BatchNorm2d-147           [-1, 1280, 7, 7]           2,560\n",
            "            ReLU-148           [-1, 1280, 7, 7]               0\n",
            "           block-149           [-1, 1280, 7, 7]               0\n",
            "AdaptiveAvgPool2d-150           [-1, 1280, 1, 1]               0\n",
            "          Linear-151                   [-1, 10]          12,810\n",
            "================================================================\n",
            "Total params: 7,844,106\n",
            "Trainable params: 7,844,106\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 88.73\n",
            "Params size (MB): 29.92\n",
            "Estimated Total Size (MB): 119.22\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}